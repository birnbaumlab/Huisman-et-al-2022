{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This script generates visualizations of 15mer hits and 9mers hits."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from Bio import AlignIO\n",
    "from Bio import SeqIO\n",
    "import numpy as np\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_ordered_nmers(uniprot, prot_dict, length):\n",
    "    #############\n",
    "    # Generate 'length'-mer peptides from whole proteome.\n",
    "    #############\n",
    "    # Uniprot: protein's uniprot identifier; used to look up protein sequencein prot_dict\n",
    "    # prot_dict: dictionary of protein uniprot ID pointing to protein sequence\n",
    "    # length: length of peptides in screen; unit length for proteome to be divided into\n",
    "    ############\n",
    "    mers = []\n",
    "    order = []\n",
    "    source=[]\n",
    "    seq = prot_dict[uniprot].seq\n",
    "    for i in range(0,len(seq)-(length-1)):\n",
    "        mers.append(str(seq[i:i+length]))\n",
    "        order.append(i+1)\n",
    "        source.append(uniprot)\n",
    "    df = pd.DataFrame({'{}mers'.format(length):mers, 'order':order,'source':source})\n",
    "    return df\n",
    "\n",
    "\n",
    "def merge_proteomes_datasets(protein_df,data,naming,mhc):\n",
    "    #############\n",
    "    # Align dataframe containing 15mers from proteome with the dataset of enrichment values for all 15mers.\n",
    "    # Call peptides as hits or not based on enrichment in doped and undoped libraries.\n",
    "    #############\n",
    "    # protein_df: dataframe containing all 15mers from proteome in order (columns: '15mers', 'order', 'source')\n",
    "    # data: dataframe containing yeast display experiment data\n",
    "    # naming: 'covid' or 'dengue' or 'netmhc'; determines which column headers to use for calculations\n",
    "    ############\n",
    "    \n",
    "    # Merge list in order with dataset \n",
    "    merged = pd.merge(left=protein_df, right=data,left_on='15mers',right_on='name',how='left')\n",
    "    merged\n",
    "       \n",
    "    \n",
    "    # Define hits: Keep hits above thresholds - indicate hits\n",
    "    if naming == 'covid':\n",
    "        print('in covid section')\n",
    "        ## COVID Naming\n",
    "        #hit using undoped\n",
    "        merged['hit u'] = merged['frac_ undoped-{} post-R2 - positive '.format(mhc)]>merged['frac_ undoped-{} post-R1 - positive '.format(mhc)]\n",
    "\n",
    "        #hit using doped\n",
    "        merged['hit d'] = (merged['count_ doped-{} post-R3 '.format(mhc)]>=10)\n",
    "\n",
    "        #hit using undoped and doped\n",
    "        merged['hit d+u'] = (merged['hit d']&merged['hit u'])\n",
    "    \n",
    "    elif naming == 'dengue': #doped hit based on rep 1\n",
    "        print('in dengue section')\n",
    "        ## Dengue Naming\n",
    "        #hit using undoped\n",
    "        merged['hit u'] = merged['{}-R2-pos_undoped_frac'.format(mhc)]>merged['{}-R1-pos_undoped_frac'.format(mhc)]\n",
    "\n",
    "        #hit using doped\n",
    "        merged['hit d'] = (merged['R3-{}_doped-rep1'.format(mhc)]>=10) # Rep1 only\n",
    "\n",
    "        #hit using undoped and doped\n",
    "        merged['hit d+u'] = (merged['hit d']&merged['hit u'])\n",
    "               \n",
    "    elif naming == 'netmhc':\n",
    "        print('in netmhc section')\n",
    "        merged['hit d+u'] = (merged['Rank DRB1_0401']<=10) \n",
    "  \n",
    "    # make a column that's variation of 'hit d+u' - if 'true', value is between 1-15 (offset so neighboring peptides are different for later visualization)\n",
    "    merged['hit mod_value'] = 0\n",
    "    merged.loc[merged['hit d+u']==1, 'hit mod_value'] = merged.loc[merged['hit d+u']==1, 'order']%15+1\n",
    "\n",
    "    return (merged)\n",
    "\n",
    "\n",
    "def trace_hits_over_aas_dropped(df, data_merged, p1_kw=False, p1_col_name=''):\n",
    "    ############\n",
    "    # For each 15mer hit in proteome, mark all 15 amino acids in it as hits.\n",
    "    # Alternatively, mark P1 location.\n",
    "    # Drop lines down to lowest y-value without causing overlap (like turning 'gravity' on)\n",
    "    # This is in a 'vertical' type format, where the proteome is stretched across all rows, 1 amino acid at a time.\n",
    "    ############\n",
    "    # df: (df_1mers) dataframe containing all '1mers' (single amino acids) from proteome in order (columns: '1mers', 'order', 'source')\n",
    "    # data_merged: dataframe containing yeast display experiment data, merged with analytical data, including 'hit mod_value', a variation of 'hit d+u'\n",
    "    # p1_kw: if 'True', mark only the P1.\n",
    "    # p1_col_name: required if p1_kw==True, to use correct column in data_merged\n",
    "    ############\n",
    "    \n",
    "    df_1mers = df.copy(deep=True)\n",
    "\n",
    "    for i in range(1,16):\n",
    "        df_1mers['mod={}'.format(str(i))]=0\n",
    "\n",
    "    mod_val = 0 # use a moving 'mod value' that increases where at in y-dimension so don't overlap other hits ('mod_val' is basically how much y-offset to use in figure)\n",
    "    gaps = 0 # count space between last hit so can drop back to 0\n",
    "    for i in range(0,len(data_merged)):\n",
    "        if data_merged.loc[data_merged['order']==i+1,'hit mod_value'].values>0:\n",
    "            if gaps>= 14: #if big gaps between the last hit and this hit, can start back at the bottom without overlapping\n",
    "                mod_val = 0\n",
    "            elif mod_val >= 15: #if have 15 or more overlapping peptides, can start back at bottom without overlapping\n",
    "                mod_val = 0\n",
    "\n",
    "            gaps = 0 #reset gap to 0 when there's a hit \n",
    "            mod_val = mod_val+1\n",
    "            \n",
    "            # do for peptides ('normal')\n",
    "            if p1_kw == False:\n",
    "                df_1mers.loc[i,'mod={}'.format(str(mod_val))] = mod_val #mark the first amino acid #Alt: .loc[df_1mers['order']==i+1,...] ('order' = 'index+1')\n",
    "                for neighbor_i in range(1,15): #to the next 14 amino acids, mark them as also a hit (only marked for P1 so far)\n",
    "                    df_1mers.loc[i+neighbor_i,'mod={}'.format(str(mod_val))]=mod_val #Alt: .loc[df_1mers['order']==i+1+neighbor_i,...]\n",
    "            # do for marking P1\n",
    "            elif p1_kw == True:\n",
    "                p1 = data_merged.loc[data_merged['order']==i+1, p1_col_name]\n",
    "                df_1mers.loc[i+p1,'mod={}'.format(str(mod_val))]=mod_val\n",
    "            \n",
    "        else: #not a hit\n",
    "            gaps+=1\n",
    "            \n",
    "    #save Y order labels as string so all must be plotted later \n",
    "    df_1mers['order_str'] = df_1mers['order'].astype(str) \n",
    "    \n",
    "    #convert zeros to NaN so won't plot and can plot continuous lines\n",
    "    for i in range(1,16):\n",
    "        df_1mers.loc[ df_1mers['mod={}'.format(str(i)) ]==0,'mod={}'.format(str(i))]=np.nan\n",
    "    \n",
    "    return df_1mers\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rename_cols(df, serotype): # rename columns so reflect the serotype\n",
    "    for col in list(df.columns):\n",
    "        df = df.rename(columns={col:col+'_'+str(serotype)})\n",
    "    return df\n",
    "\n",
    "def find(s, ch): # simple search function: https://stackoverflow.com/questions/11122291/how-to-find-char-in-string-and-get-all-the-indexes\n",
    "    return [i for i, ltr in enumerate(s) if ltr == ch]\n",
    "\n",
    "def add_gaps(df, uniprot,serotype,alignment):\n",
    "    ###########\n",
    "    # When proteins are aligned (as in 'alignment'), there are frequently gaps from insertions/deletions in a protein.\n",
    "    # This script adds gaps to dataframes ('df') of ordered peptides by moving their ordering in 'order' to \n",
    "    # new column 'order+gaps' to reflect their alignment in 'alignment'. \n",
    "    # Returns updated df with 'order+gaps' column\n",
    "    ###########\n",
    "    # df: dataframe containing ordered peptides\n",
    "    # uniprot: uniprot ID corresponding to a protein of interest, as labelled in 'alignment'\n",
    "    # alignment: alignment of proteins of interest\n",
    "    # serotype: string that is in the header of df and will use in header ['order_'+serotype]\n",
    "    ###########\n",
    "    for record in alignment:\n",
    "        if record.id == uniprot:\n",
    "            aligned_seq = record.seq\n",
    "            print('found sequence: ',record.id)\n",
    "    gap_locations = find(aligned_seq,'-') #indexed at 0 #find the gaps\n",
    "    \n",
    "    df['order+gaps_'+str(serotype)]=df['order_'+str(serotype)] #order in the alignment\n",
    "    for i in gap_locations:\n",
    "        df.loc[df['order+gaps_'+str(serotype)]>=i+1,'order+gaps_'+str(serotype)]+=1 #increase the order by 1\n",
    "\n",
    "    return df\n",
    "\n",
    "def do_it(uniprot, fname,serotype,virus,data,allele,kw_skipP1=False):\n",
    "    ######\n",
    "    # Function to call other functions: outputs dataframes of ordered 1mers and 9mers, \n",
    "    # and 15mers merged with data from yeast display experiments\n",
    "    ######\n",
    "    # uniprot: uniprot name of protein of interest\n",
    "    # fname: FASTA file name, containing the sequence of protein named in 'uniprot' variable\n",
    "    # serotype: 1-4 for dengue or 1-2 for covid (for SARS-CoV or SARS-CoV-2)\n",
    "    # virus: 'covid' or 'dengue'\n",
    "    # data: dataframe of yeast data\n",
    "    # allele: HLA-DR401/402/404 (401, 402, 402)\n",
    "    # kw_skipP1: if False (default), will include a marking for where P1 of the cluster-identified core is\n",
    "    ######\n",
    "    \n",
    "    prot_dict = SeqIO.to_dict(SeqIO.parse(fname, \"fasta\"))#Import source protein sequences ##Dictionary of the uniprot IDs and their corresponding protein sequences\n",
    "    \n",
    "    df_15mers = extract_ordered_nmers(uniprot, prot_dict, length=15) #15mers\n",
    "    data_merged = merge_proteomes_datasets(df_15mers,data,virus,allele) #merge ordered 15mers with yeast data\n",
    "\n",
    "    df_1mers = extract_ordered_nmers(uniprot, prot_dict, length=1) #1mers\n",
    "    df_1mers = trace_hits_over_aas_dropped(df_1mers, data_merged) #mark where 15mer hits are\n",
    "    \n",
    "    df_9mers = extract_ordered_nmers(uniprot, prot_dict, length=9) #9mers \n",
    " \n",
    "    #highlight P1 of cores\n",
    "    if kw_skipP1!=True:\n",
    "        df_1mers_p1 = trace_hits_over_aas_dropped(df_1mers, data_merged, True, 'P1_{}'.format(allele))\n",
    "        df_1mers_p1 = rename_cols(df_1mers_p1, 'p1')\n",
    "        df_1mers = pd.merge(left=df_1mers, right=df_1mers_p1, left_on='order',right_on='order_p1')\n",
    "        df_1mers = rename_cols(df_1mers, serotype)\n",
    "        \n",
    "    return data_merged, df_1mers, df_9mers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###### for 9mer smoothing ############\n",
    "def NofSeven(merged, df_9mers):\n",
    "    ########\n",
    "    # For smoothing to 9mer sequences by determining how many neighboring 15mers a given 9mer enriches in.\n",
    "    # For most peptides (excluding edge peptides), a 9mer will show up in seven 15mer peptides.\n",
    "    # Uses a dataframe of 9mer peptides and notes hits there.\n",
    "    ########\n",
    "    # merged: dataframe of ordered 15mer peptides with yeast display enrichment information.\n",
    "    # df_9mers: dataframe of ordered 9mer peptides.\n",
    "    # Outputs updated df_9mers with information about how many of 7 15mers are hits.\n",
    "    ########\n",
    "    \n",
    "    #Denote #/7 peptides present in a row\n",
    "    df_9mers['n hits of 7-d+u']=0\n",
    "    df_9mers['n hits of 7-d']=0\n",
    "    df_9mers['n hits of 7-u']=0\n",
    "    df_9mers['n hits of 7-d only']=0 #hits in doped, but not undoped\n",
    "    df_9mers['n hits of 7-u only']=0 #hits in undoped, but not doped\n",
    "\n",
    "    #Count # of peptides that 9mer has hits in for peptides (want at least 5/7 in sliding window to be hits)\n",
    "    for i in range(int(np.min(df_9mers['order'])),int(np.max(df_9mers['order'])+1)): \n",
    "        #create a boolean, where 'true' is 'order' in 15mer which contain 9mer of interest\n",
    "        surrounding=(merged['order']>=i-6) & (merged['order']<=i)\n",
    "                \n",
    "        df_9mers.loc[df_9mers['order']==i,'n hits of 7-d+u']=np.sum(merged[surrounding]['hit d+u'])\n",
    "        df_9mers.loc[df_9mers['order']==i,'n hits of 7-d']=np.sum(merged[surrounding]['hit d'])\n",
    "        df_9mers.loc[df_9mers['order']==i,'n hits of 7-u']=np.sum(merged[surrounding]['hit u'])\n",
    "        df_9mers.loc[df_9mers['order']==i,'n hits of 7-d only']=np.sum((merged[surrounding]['hit d']) & (~merged[surrounding]['hit u']))\n",
    "        df_9mers.loc[df_9mers['order']==i,'n hits of 7-u only']=np.sum((merged[surrounding]['hit u']) & (~merged[surrounding]['hit d']))\n",
    "                \n",
    "        if i%100 == 0:\n",
    "            print(i)\n",
    "\n",
    "    return df_9mers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example of 15mer hits with intermediate dataframes shown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## SARS-CoV-2 ###\n",
    "data = pd.read_csv('../twist_covid_filtered+normalized_counts.csv').fillna(0)\n",
    "data.drop(columns='Unnamed: 0',inplace=True)\n",
    "data.drop(columns='Unnamed: 0.1',inplace=True)\n",
    "data=data[data['doped_match']!='match'] #keep only covid peptides\n",
    "\n",
    "cores = pd.read_csv('test-v4_401_twist_covid_filtered+normalized_counts_d+u.csv')\n",
    "display(cores)\n",
    "data = pd.merge(left=data, right=cores, left_on='name',right_on='sequence',how='left') #merge so captures 'P1'\n",
    "data.drop(columns=['sequence','count'],inplace=True)\n",
    "display(data)\n",
    "\n",
    "\n",
    "uniprot = 'sp|P0DTC9|NCAP_WCPV'\n",
    "prot_dict = SeqIO.to_dict(SeqIO.parse('../../nCov.fasta', \"fasta\"))#Import source protein sequences ##Dictionary of the uniprot IDs and their corresponding protein sequences\n",
    "\n",
    "df_15mers = extract_ordered_nmers(uniprot, prot_dict, length=15)\n",
    "display(df_15mers)\n",
    "\n",
    "df_1mers = extract_ordered_nmers(uniprot, prot_dict, length=1)\n",
    "display(df_1mers)\n",
    "\n",
    "data_merged = merge_proteomes_datasets(df_15mers,data,'covid','401')\n",
    "display(data_merged)\n",
    "\n",
    "df_1mers_marked = trace_hits_over_aas_dropped(df_1mers, data_merged)\n",
    "display(df_1mers_marked)\n",
    "\n",
    "df_1mers_marked_p1 = trace_hits_over_aas_dropped(df_1mers, data_merged, True,'P1')\n",
    "display(df_1mers_marked_p1)\n",
    "\n",
    "\n",
    "###################################### PLOT ##################################\n",
    "plt.rcParams.update({'font.size': 18})\n",
    "\n",
    "for index in [0,85,170,255,340]:\n",
    "    fig, ax1 = plt.subplots(figsize=(18,1))\n",
    "    for i in range(1,16):\n",
    "            \n",
    "        plt.plot(df_1mers_marked['order_str'],df_1mers_marked['mod={}'.format(str(i))], c='blue')\n",
    "        plt.plot(df_1mers_marked_p1['order_str'],df_1mers_marked_p1['mod={}'.format(str(i))], c='red',marker='|')\n",
    "\n",
    "\n",
    "    ax1.set_xticklabels(df_1mers_marked['1mers']) ## label with amino acid\n",
    "\n",
    "    plt.xlim(index,index+84)\n",
    "\n",
    "    ax1.spines['top'].set_visible(False)\n",
    "    ax1.spines['right'].set_visible(False)\n",
    "    ax1.spines['left'].set_visible(False)\n",
    "    plt.yticks([])  \n",
    "    plt.xticks(fontname='Andale Mono')\n",
    "    \n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 9mer smoothing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9mer smoothing: Spike: CoV+CoV-2 for 3 alleles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def smooth_each_allele(merged_2_in, merged_1_in, df_9mers_2_in, df_9mers_1_in):\n",
    "    ########\n",
    "    # Function specific for doing 9mer smoothing on SARS-CoV/SARS-CoV-2 Spike proteins:\n",
    "    # Put the processing into a function so can easily repeat for each allele (HLA-DR401/402/404)\n",
    "    ########\n",
    "    # merged_2_in:   dataframe containing ordered 15mer peptides and yeast data; for SARS-CoV-2\n",
    "    # merged_1_in:   dataframe containing ordered 15mer peptides and yeast data; for SARS-CoV\n",
    "    # df_9mers_2_in: dataframe containing ordered 9mer peptides; for SARS-CoV-2\n",
    "    # df_9mers_1_in: dataframe containing ordered 9mer peptides; for SARS-CoV\n",
    "    # Outputs a dataframe of 9mer peptides merged between the two viruses.\n",
    "    ########\n",
    "    merged_2_in = NofSeven(merged_2_in, df_9mers_2_in) #outputs the 9mers\n",
    "    merged_1_in = NofSeven(merged_1_in, df_9mers_1_in) #outputs the 9mers\n",
    "    \n",
    "    merged_2 = rename_cols(merged_2_in, 2)\n",
    "    merged_1 = rename_cols(merged_1_in, 1)\n",
    "\n",
    "    merged_2 = add_gaps(merged_2, 'sp|P0DTC2|SPIKE_WCPV', 2,alignment)\n",
    "    merged_1 = add_gaps(merged_1, 'sp|P59594|SPIKE_CVHSA',1,alignment)\n",
    "    \n",
    "    \n",
    "    ## Merge all viruses and process\n",
    "    #make dataframe with all order values so can order to this:\n",
    "    merged = pd.DataFrame({'overall_order':range(1,alignment.get_alignment_length()-7)}) # DO RANGE(0, len-7) because need amino acid at end of last peptide\n",
    "\n",
    "    #combine both viruses\n",
    "    merged = pd.merge(left=merged, right=merged_2, left_on='overall_order',right_on='order+gaps_2',how='outer')\n",
    "    merged = pd.merge(left=merged, right=merged_1, left_on='overall_order',right_on='order+gaps_1',how='outer')\n",
    "\n",
    "    #binning hits - binary yes/no if >=5 of 7 are hits\n",
    "    for i in ['1','2']:\n",
    "        merged['n hits of 7-d+u_{}-bin'.format(i)] = 1*(merged['n hits of 7-d+u_{}'.format(i)]>=5)\n",
    "\n",
    "    # combine amino acids for making X-tick labels that are basically the alignment\n",
    "    for i in [1,2]:\n",
    "        merged['9mers_'+str(i)].fillna('-',inplace=True)\n",
    "    \n",
    "    return merged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import data and import P1 data and merge with yeast data\n",
    "data = pd.read_csv('../twist_covid_filtered+normalized_counts.csv').fillna(0)\n",
    "data.drop(columns='Unnamed: 0',inplace=True)\n",
    "data.drop(columns='Unnamed: 0.1',inplace=True)\n",
    "data=data[data['doped_match']!='match'] #keep only covid peptides\n",
    "display(data)\n",
    "\n",
    "\n",
    "# read in aligned sequences - aligned via ClustalOmega\n",
    "alignment = AlignIO.read('SARS-CoV+SARS-CoV-2_Spike_clustalo-I20211008-141806-0217-21876811-p1m.clustal_num','clustal')\n",
    "\n",
    "\n",
    "## SARS-CoV-2 ###\n",
    "uniprot = 'sp|P0DTC2|SPIKE_WCPV'\n",
    "fname = '../../nCov.fasta'\n",
    "data_merged_2_401, df_1mers_2_401, df_9mers_2_401 = do_it(uniprot, fname, 2,'covid',data,allele='401',kw_skipP1=True)\n",
    "data_merged_2_402, df_1mers_2_402, df_9mers_2_402 = do_it(uniprot, fname, 2,'covid',data,allele='402',kw_skipP1=True)\n",
    "data_merged_2_404, df_1mers_2_404, df_9mers_2_404 = do_it(uniprot, fname, 2,'covid',data,allele='404',kw_skipP1=True)\n",
    "\n",
    "data_merged_2_401.to_csv('SARS-CoV-2 Spike protein 15mers ordered-HLA-DR401 hits noted.csv')\n",
    "\n",
    "\n",
    "## SARS-CoV\"-1\" ###\n",
    "uniprot = 'sp|P59594|SPIKE_CVHSA'\n",
    "fname = '../../uniprot-proteome_UP000000354 SARS-CoV-1.fasta'\n",
    "data_merged_1_401, df_1mers_1_401, df_9mers_1_401 = do_it(uniprot, fname, 1,'covid',data,allele='401',kw_skipP1=True)\n",
    "data_merged_1_402, df_1mers_1_402, df_9mers_1_402 = do_it(uniprot, fname, 1,'covid',data,allele='402',kw_skipP1=True)\n",
    "data_merged_1_404, df_1mers_1_404, df_9mers_1_404 = do_it(uniprot, fname, 1,'covid',data,allele='404',kw_skipP1=True)\n",
    "\n",
    "\n",
    "\n",
    "#9mer smoothing\n",
    "merged_401 = smooth_each_allele(data_merged_2_401, data_merged_1_401, df_9mers_2_401, df_9mers_1_401)\n",
    "merged_402 = smooth_each_allele(data_merged_2_402, data_merged_1_402, df_9mers_2_402, df_9mers_1_402)\n",
    "merged_404 = smooth_each_allele(data_merged_2_404, data_merged_1_404, df_9mers_2_404, df_9mers_1_404)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Visualize overall\n",
    "\n",
    "#number of serotypes that match \n",
    "merged_401['matched serotypes max'] = 1*(merged_401['9mers_1']==merged_401['9mers_2'])\n",
    "\n",
    "#more minimilistic view:\n",
    "plt.figure(figsize=(28,4))\n",
    "plt.scatter(merged_401['overall_order'],merged_401['n hits of 7-d+u_1-bin']*1.0,c='blue',marker='|',alpha=0.5)\n",
    "plt.scatter(merged_401['overall_order'],merged_401['n hits of 7-d+u_2-bin']*1.1,c='blue',marker='|')\n",
    "\n",
    "plt.scatter(merged_402['overall_order'],merged_402['n hits of 7-d+u_1-bin']*1.2,c='red',marker='|',alpha=0.5)\n",
    "plt.scatter(merged_402['overall_order'],merged_402['n hits of 7-d+u_2-bin']*1.3,c='red',marker='|')\n",
    "\n",
    "plt.scatter(merged_404['overall_order'],merged_404['n hits of 7-d+u_1-bin']*1.4,c='grey',marker='|',alpha=0.5)\n",
    "plt.scatter(merged_404['overall_order'],merged_404['n hits of 7-d+u_2-bin']*1.5,c='grey',marker='|')\n",
    "\n",
    "\n",
    "plt.scatter(merged_401['overall_order'],merged_401['matched serotypes max']*0.1+1.7*(merged_401['matched serotypes max']>0),c='black',marker='|') #can do 'plot' too\n",
    "plt.xlim(-10,1300)\n",
    "plt.ylim(0.1, 3.)\n",
    "\n",
    "plt.xticks(fontname='Arial')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9mer smoothing: SARS-CoV-2 Nucleocapsid mountain plot for HLA-DR401"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Make Nucleocapsid mountain plot \n",
    "\n",
    "# Import yeast data\n",
    "data = pd.read_csv('../twist_covid_filtered+normalized_counts.csv').fillna(0)\n",
    "data.drop(columns='Unnamed: 0',inplace=True)\n",
    "data.drop(columns='Unnamed: 0.1',inplace=True)\n",
    "data=data[data['doped_match']!='match'] #keep only covid peptides\n",
    "\n",
    "\n",
    "# read in aligned sequences - aligned via ClustalOmega\n",
    "alignment = AlignIO.read('SARS-CoV+SARS-CoV-2_NCAP_clustalo-I20211008-141842-0188-61142883-p2m.clustal_num','clustal')\n",
    "\n",
    "\n",
    "## SARS-CoV-2 ###\n",
    "uniprot = 'sp|P0DTC9|NCAP_WCPV'\n",
    "fname = '../../nCov.fasta'\n",
    "data_merged_2_401, df_1mers_2_401, df_9mers_2_401 = do_it(uniprot, fname, 2,'covid',data,allele='401',kw_skipP1=True) #test no P1 processing\n",
    "display(data_merged_2_401)\n",
    "\n",
    "data_merged_2_401.to_csv('SARS-CoV-2 NCAP protein 15mers ordered-HLA-DR401 hits noted.csv')\n",
    "\n",
    "#9mer smoothing\n",
    "merged = NofSeven(data_merged_2_401, df_9mers_2_401) #actually outputs the 9mers\n",
    "display(merged)\n",
    "\n",
    "## Do on dataframe with no gaps added\n",
    "# Mountain plots:\n",
    "\n",
    "color_dict = {'n hits of 7-d+u':'black','n hits of 7-d only':'red','n hits of 7-u only':'blue'}\n",
    "alpha_dict = {'n hits of 7-d+u':1,'n hits of 7-d only':0.5,'n hits of 7-u only':0.5}\n",
    "legend_dict = {'n hits of 7-d+u':'Doped+Undoped','n hits of 7-d only':'Doped only','n hits of 7-u only':'Undoped only'}\n",
    "\n",
    "\n",
    "for index in [0,105,210,315]:#,200,300,400,500]:\n",
    "    fig, ax1 = plt.subplots(figsize=(24,2))\n",
    "    \n",
    "    #update font sizes for subplots\n",
    "    for item in ([ax1.title, ax1.xaxis.label, ax1.yaxis.label] +\n",
    "                 ax1.get_xticklabels() + ax1.get_yticklabels()):\n",
    "        item.set_fontsize(14)\n",
    "\n",
    "    # PLOT\n",
    "    bottom = len(merged) * [0]\n",
    "    for x in ['n hits of 7-d+u','n hits of 7-d only','n hits of 7-u only']: \n",
    "        ax1.bar(merged['9mers'],merged[x],bottom=bottom,label=legend_dict[x],color=color_dict[x],alpha=alpha_dict[x],)\n",
    "        bottom+=merged[x]\n",
    "    \n",
    "    plt.xticks(rotation = 90)\n",
    "    plt.xticks(fontname='Andale Mono')\n",
    "    \n",
    "    plt.ylim(0,8)\n",
    "    plt.xlim(index,index+104)\n",
    "    plt.show()\n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9mer smoothing: Dengue: HLA-DR401, 4 serotypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## MAKE SMOOTHED BIG PICTURE DENGUE FIGURE\n",
    "#edit input file:\n",
    "data_dengue = pd.read_csv('twist_doped+undoped_combined_with-fractions_v2e.csv').fillna(0)\n",
    "\n",
    "\n",
    "#calculate fractions for undoped rounds\n",
    "for i in ['1','2','3']:\n",
    "    data_dengue['401-R{}-pos_undoped_frac'.format(i)] = data_dengue['401-R{}-pos_undoped'.format(i)]/np.sum(data_dengue['401-R{}-pos_undoped'.format(i)])\n",
    "\n",
    "data_dengue.rename(columns={'aa':'name','name':'from'}, inplace=True) #to match covid data processing\n",
    "display(data_dengue)\n",
    "\n",
    "# read in aligned sequences - aligned via ClustalOmega\n",
    "alignment_dengue = AlignIO.read('clustalo-I20210910-195934-0821-95132107-p2m.clustal_num','clustal')\n",
    "\n",
    "directory = '/Proteome Peptides/Dengue - used to generate lists'\n",
    "\n",
    "## Dengue 1 ###\n",
    "uniprot = 'sp|P17763|POLG_DEN1W'\n",
    "fname = '/dengue_type1_UP000002500.fasta'\n",
    "data_merged_1, df_1mers_1, df_9mers_1 = do_it(uniprot, directory+fname, 1,'dengue',data_dengue,allele='401',kw_skipP1=True)\n",
    "display(df_9mers_1)\n",
    "data_merged_1.to_csv('Dengue serotype1 protein 15mers ordered-HLA-DR401 hits noted.csv')\n",
    "    \n",
    "## Dengue 2 ###\n",
    "uniprot = 'tr|O09234|O09234_DEN26'\n",
    "fname = '/dengue_type2_UP000180751.fasta'\n",
    "data_merged_2, df_1mers_2, df_9mers_2 = do_it(uniprot, directory+fname, 2,'dengue',data_dengue,allele='401',kw_skipP1=True)\n",
    "\n",
    "## Dengue 3 ###\n",
    "uniprot = 'sp|P27915|POLG_DEN3P'\n",
    "fname = '/dengue_type3_UP000007200.fasta'\n",
    "data_merged_3, df_1mers_3, df_9mers_3 = do_it(uniprot, directory+fname, 3,'dengue',data_dengue,allele='401',kw_skipP1=True)\n",
    "\n",
    "## Dengue 4 ###\n",
    "uniprot = 'sp|Q58HT7|POLG_DEN4P'\n",
    "fname = '/dengue_type4_UP000000275.fasta'\n",
    "data_merged_4, df_1mers_4, df_9mers_4 = do_it(uniprot, directory+fname, 4,'dengue',data_dengue,allele='401',kw_skipP1=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#dengue version of 'smooth_each_allele', except don't need function to do for each allele (only need HLA-DR401 for figure)\n",
    "\n",
    "merged_1_in = NofSeven(data_merged_1, df_9mers_1) #actually outputs the 9mers\n",
    "merged_2_in = NofSeven(data_merged_2, df_9mers_2) #actually outputs the 9mers\n",
    "merged_3_in = NofSeven(data_merged_3, df_9mers_3) #actually outputs the 9mers\n",
    "merged_4_in = NofSeven(data_merged_4, df_9mers_4) #actually outputs the 9mers\n",
    "\n",
    "merged_1 = rename_cols(merged_1_in, 1)\n",
    "merged_2 = rename_cols(merged_2_in, 2)\n",
    "merged_3 = rename_cols(merged_3_in, 3)\n",
    "merged_4 = rename_cols(merged_4_in, 4)\n",
    "\n",
    "merged_1 = add_gaps(merged_1, 'sp|P17763|POLG_DEN1W',  1,alignment_dengue)\n",
    "merged_2 = add_gaps(merged_2, 'tr|O09234|O09234_DEN26',2,alignment_dengue)\n",
    "merged_3 = add_gaps(merged_3, 'sp|P27915|POLG_DEN3P',  3,alignment_dengue)\n",
    "merged_4 = add_gaps(merged_4, 'sp|Q58HT7|POLG_DEN4P',  4,alignment_dengue)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## Merge all viruses and process\n",
    "#make dataframe with order values from alignment so can order to this:\n",
    "merged = pd.DataFrame({'overall_order':range(1,alignment_dengue.get_alignment_length()-7)}) # DO RANGE(0, len-7) because need amino acid at end of last peptide\n",
    "\n",
    "#combine viruses\n",
    "merged = pd.merge(left=merged, right=merged_1, left_on='overall_order',right_on='order+gaps_1',how='outer')\n",
    "merged = pd.merge(left=merged, right=merged_2, left_on='overall_order',right_on='order+gaps_2',how='outer')\n",
    "merged = pd.merge(left=merged, right=merged_3, left_on='overall_order',right_on='order+gaps_3',how='outer')\n",
    "merged = pd.merge(left=merged, right=merged_4, left_on='overall_order',right_on='order+gaps_4',how='outer')\n",
    "\n",
    "#binning hits - binary yes/no if >=5 of 7 are hits\n",
    "for i in ['1','2','3','4']:\n",
    "    merged['n hits of 7-d+u_{}-bin'.format(i)] = 1*(merged['n hits of 7-d+u_{}'.format(i)]>=5)\n",
    "\n",
    "\n",
    "#number of serotypes that match -- do by using each as baseline then taking max\n",
    "merged['match serotype1'] = 1*(merged['9mers_1']==merged['9mers_2']) + 1*(merged['9mers_1']==merged['9mers_3']) +1*(merged['9mers_1']==merged['9mers_4'])\n",
    "merged['match serotype2'] = 1*(merged['9mers_2']==merged['9mers_1']) + 1*(merged['9mers_2']==merged['9mers_3']) +1*(merged['9mers_2']==merged['9mers_4'])\n",
    "merged['match serotype3'] = 1*(merged['9mers_3']==merged['9mers_1']) + 1*(merged['9mers_3']==merged['9mers_2']) +1*(merged['9mers_3']==merged['9mers_4'])\n",
    "merged['match serotype4'] = 1*(merged['9mers_4']==merged['9mers_1']) + 1*(merged['9mers_4']==merged['9mers_2']) +1*(merged['9mers_4']==merged['9mers_3'])\n",
    "merged['matched serotypes max'] = merged[['match serotype1','match serotype2','match serotype3','match serotype4']].max(axis=1)\n",
    "merged\n",
    "\n",
    "#save the order as string (new column):\n",
    "merged['overall_order_str'] = merged['overall_order'].astype(str) #have to convert to string in order for all values to show up on x-axis to be replaced by AAs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#how do positions along Dengue Serotype1 correspond to 'overall_order' positions?\n",
    "#from https://www.uniprot.org/uniprot/P17763 ('PTM/Processing' section)\n",
    "#last 9mer included in sequences: \n",
    "# [..114] = [LMLLPTALA]\n",
    "# [..280] = [LMLVTPSMA]\n",
    "# [..775] = [LYLGVMVQA]\n",
    "# [..1127] =[NLVKSMVSA]\n",
    "# [..1345] =[TENKIWGRK]\n",
    "# [..1475] =[YFWQKKKQR]\n",
    "# [..2094] =[FKEFAAGRR]\n",
    "# [..2221] =[LIPEPDRQR]\n",
    "# [..2244] =[LFMILTAAA] - signal peptide for NS4B\n",
    "# [..2493] =[MKSLGGGRR]\n",
    "# [..3392] =[ESDPEGALW]\n",
    "\n",
    "last_9mer_dict = {114:'LMLLPTALA',280:'LMLVTPSMA',775:'LYLGVMVQA',1127:'NLVKSMVSA',\n",
    "                  1345:'TENKIWGRK',1475:'YFWQKKKQR',2094:'FKEFAAGRR',\n",
    "                  2221:'LIPEPDRQR',2493:'MKSLGGGRR',3392:'ESDPEGALW'}\n",
    "\n",
    "boundaries = [[1]]\n",
    "for i in [114,280,775,1127,1345,1475,2094,2221,2493,3392]:\n",
    "    x = list(merged[merged['9mers_1']==last_9mer_dict[i]]['overall_order'])\n",
    "    print(i, x)\n",
    "    boundaries.append(x)\n",
    "    \n",
    "boundaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Visualize overall 9mer hits and conservation\n",
    "\n",
    "fig, ax1 = plt.subplots(figsize=(20,4))\n",
    "\n",
    "for item in ([ax1.title, ax1.xaxis.label, ax1.yaxis.label] +\n",
    "             ax1.get_xticklabels() + ax1.get_yticklabels()):\n",
    "    item.set_fontsize(15)\n",
    "    \n",
    "plt.scatter(merged['overall_order'],merged['n hits of 7-d+u_1-bin'], c='blue',marker='|')\n",
    "plt.scatter(merged['overall_order'],merged['n hits of 7-d+u_2-bin']*1.1,c='purple',marker='|')\n",
    "plt.scatter(merged['overall_order'],merged['n hits of 7-d+u_3-bin']*1.2,c='red',marker='|')\n",
    "plt.scatter(merged['overall_order'],merged['n hits of 7-d+u_4-bin']*1.3,c='grey',marker='|')\n",
    "\n",
    "plt.scatter(merged['overall_order'],merged['matched serotypes max']*0.1+1.5*(merged['matched serotypes max']>0),c='black',marker='|') #can do 'plot' too\n",
    "\n",
    "#https://www.uniprot.org/uniprot/P17763 -- show boundaries between regions in genome\n",
    "plt.scatter(boundaries,[0.8,0.8,0.8,0.8,0.8,0.8,0.8,0.8,0.8,0.8,0.8],c='black',marker='|') #plot breaks where different regions change (note 9mers, so line up is 1AA:9AA stretch)\n",
    "\n",
    "#https://www.uniprot.org/uniprot/P17763 -- show general boundaries for where do zoom-in insets\n",
    "plt.scatter([3259,3282,1873,1896,389,412],[0.2,0.2,0.2,0.2,0.2,0.2],c='black',marker='|') #plot breaks where different regions change (note 9mers, so line up is 1AA:9AA stretch)\n",
    "\n",
    "\n",
    "plt.xlim(-10,3410)\n",
    "plt.ylim(0.1, 3)\n",
    "\n",
    "ax1.spines['top'].set_visible(False)\n",
    "ax1.spines['right'].set_visible(False)\n",
    "ax1.spines['left'].set_visible(False)\n",
    "plt.yticks([0.25,1,1.1,1.2,1.3,1.5,1.6,1.7,1.8])\n",
    "ax1.set_yticklabels(['','Serotype 1','Serotype 2','Serotype 3','Serotype 4','','Conserved 2/4','Conserved 3/4','Conserved 4/4']) \n",
    "plt.xticks(fontname='Arial')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SARS-CoV-2 Spike -  with NetMHCIIpan4.0 predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## SARS-CoV-2 Spike ##\n",
    "uniprot = 'sp|P0DTC2|SPIKE_WCPV'\n",
    "prot_dict = SeqIO.to_dict(SeqIO.parse('../../nCov.fasta', \"fasta\"))#Import source protein sequences ##Dictionary of the uniprot IDs and their corresponding protein sequences\n",
    "\n",
    "df_15mers = extract_ordered_nmers(uniprot, prot_dict, length=15)\n",
    "\n",
    "data_merged = merge_proteomes_datasets(df_15mers,data,'covid','401')\n",
    "display(data_merged)\n",
    "\n",
    "df_1mers = extract_ordered_nmers(uniprot, prot_dict, length=1)\n",
    "display(df_1mers)\n",
    "\n",
    "df_1mers_marked = trace_hits_over_aas_dropped(df_1mers, data_merged)\n",
    "display(df_1mers_marked)\n",
    "\n",
    "\n",
    "\n",
    "## NetMHC data processing ##\n",
    "#NetMHCIIpan4.0 predictions using web-interface predictions \n",
    "\n",
    "flanked = pd.read_csv('NetMHCIIpan4_DR401_SARS-CoV-2_Spike-flanked.csv')\n",
    "flanked['name'] = flanked['Peptide'].str[1:16] #peptides with flanking sequence, so extract 15mers for merging purposes:\n",
    "\n",
    "unflanked = pd.read_csv('NetMHCIIpan4_DR401_SARS-CoV-2_Spike.csv')\n",
    "unflanked['name'] = unflanked['Peptide']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot:\n",
    "for netmhc in [flanked]:\n",
    "\n",
    "    #make 1mer dataframe for Spike protein again\n",
    "    uniprot = 'sp|P0DTC2|SPIKE_WCPV'\n",
    "    prot_dict = SeqIO.to_dict(SeqIO.parse('../../nCov.fasta', \"fasta\"))#Import source protein sequences ##Dictionary of the uniprot IDs and their corresponding protein sequences\n",
    "    df_15mers = extract_ordered_nmers(uniprot, prot_dict, length=15)\n",
    "    df_1mers = extract_ordered_nmers(uniprot, prot_dict, length=1)\n",
    "\n",
    "    \n",
    "    data_merged_netmhc = merge_proteomes_datasets(df_15mers,netmhc,'netmhc','401')\n",
    "    df_1mers_marked_netmhc = trace_hits_over_aas_dropped(df_1mers, data_merged_netmhc)\n",
    "\n",
    "\n",
    "    plt.rcParams.update({'font.size': 12})\n",
    "    for index in [0,140,280,420,560,700,840,980,1120,1260]:\n",
    "        fig, ax1 = plt.subplots(figsize=(18,2))\n",
    "        for i in range(1,16): \n",
    "            plt.plot(df_1mers_marked['order_str'],df_1mers_marked['mod={}'.format(str(i))], c='#009ADE')#,marker='_')#,s=100)\n",
    "            plt.plot(df_1mers_marked_netmhc['order_str'],df_1mers_marked_netmhc['mod={}'.format(str(i))]+17, c='#FF1F5B')#,marker='_')\n",
    "            \n",
    "        ax1.set_xticklabels(df_1mers_marked['1mers']) ## label with amino acid\n",
    "\n",
    "        plt.xlim(index,index+139)#99)#139)\n",
    "        plt.ylim(0, 35)\n",
    "\n",
    "        ax1.spines['top'].set_visible(False)\n",
    "        ax1.spines['right'].set_visible(False)\n",
    "        ax1.spines['left'].set_visible(False)\n",
    "        plt.yticks([])  \n",
    "        plt.xticks(fontname='Andale Mono')\n",
    "        plt.show()\n",
    "    \n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Make version that is specific to regions and only shows peptides that contain a given 9mer "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SARS-CoV-1/2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## ADAPTED FOR TARGETED FIGURES\n",
    "#function to call other functions: for both Dengue and Covid:\n",
    "def do_it_targeted(uniprot, fname,serotype,virus,data,mhc,directory=''):\n",
    "    prot_dict = SeqIO.to_dict(SeqIO.parse(directory+fname, \"fasta\"))#Import source protein sequences ##Dictionary of the uniprot IDs and their corresponding protein sequences\n",
    "    df_15mers = extract_ordered_nmers(uniprot, prot_dict, length=15) #15mers\n",
    "    data_merged = merge_proteomes_datasets(df_15mers,data,virus,mhc) \n",
    "    \n",
    "    #blank everything except the desired area:\n",
    "    data_merged.loc[~((data_merged['order']>serotype_blank_min[serotype])&(data_merged['order']<serotype_blank_max[serotype])),'hit mod_value'] = 0\n",
    "    \n",
    "    df_1mers = extract_ordered_nmers(uniprot, prot_dict, length=1) #1mers\n",
    "    df_1mers = trace_hits_over_aas_dropped(df_1mers, data_merged) \n",
    "    \n",
    "    df_1mers = rename_cols(df_1mers, serotype)\n",
    "    return data_merged, df_1mers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## SARS-CoV-2 Spike ##\n",
    "def everything_else_covid(narrow_kw=''):\n",
    "    # narrow_kw = 'narrow' will make the X-dimension length right for non-linker peptides\n",
    "    \n",
    "    ## SARS-CoV Spike ##\n",
    "    print('CoV-1 Spike')\n",
    "    uniprot = 'sp|P59594|SPIKE_CVHSA'\n",
    "    fname = '../../uniprot-proteome_UP000000354 SARS-CoV-1.fasta'\n",
    "   \n",
    "    data_merged_1_401, df_1mers_1_401 = do_it_targeted(uniprot, fname, 1,'covid',data,'401')\n",
    "    data_merged_1_402, df_1mers_1_402 = do_it_targeted(uniprot, fname, 1,'covid',data,'402')\n",
    "    data_merged_1_404, df_1mers_1_404 = do_it_targeted(uniprot, fname, 1,'covid',data,'404')\n",
    "\n",
    "    ## SARS-CoV-2 Spike ##\n",
    "    print('CoV-2 Spike')\n",
    "    uniprot = 'sp|P0DTC2|SPIKE_WCPV'\n",
    "    fname = '../../nCov.fasta'\n",
    "    \n",
    "    data_merged_2_401, df_1mers_2_401 = do_it_targeted(uniprot, fname, 2,'covid',data,'401')\n",
    "    data_merged_2_402, df_1mers_2_402 = do_it_targeted(uniprot, fname, 2,'covid',data,'402')\n",
    "    data_merged_2_404, df_1mers_2_404 = do_it_targeted(uniprot, fname, 2,'covid',data,'404')\n",
    "\n",
    "    \n",
    "    \n",
    "    # read in aligned sequences - aligned via ClustalOmega\n",
    "    alignment = AlignIO.read('SARS-CoV+SARS-CoV-2_Spike_clustalo-I20211008-141806-0217-21876811-p1m.clustal_num','clustal')\n",
    "\n",
    "\n",
    "    # find where there are gaps in alignment and add gaps in the ordered dataframe\n",
    "    df_1mers_1_401 = add_gaps(df_1mers_1_401, 'sp|P59594|SPIKE_CVHSA',1,alignment)\n",
    "    df_1mers_1_402 = add_gaps(df_1mers_1_402, 'sp|P59594|SPIKE_CVHSA',1,alignment)\n",
    "    df_1mers_1_404 = add_gaps(df_1mers_1_404, 'sp|P59594|SPIKE_CVHSA',1,alignment)\n",
    "    df_1mers_2_401 = add_gaps(df_1mers_2_401, 'sp|P0DTC2|SPIKE_WCPV' ,2,alignment)\n",
    "    df_1mers_2_402 = add_gaps(df_1mers_2_402, 'sp|P0DTC2|SPIKE_WCPV' ,2,alignment)\n",
    "    df_1mers_2_404 = add_gaps(df_1mers_2_404, 'sp|P0DTC2|SPIKE_WCPV' ,2,alignment)\n",
    "\n",
    "    \n",
    "    df_1mers_1_401 = rename_cols(df_1mers_1_401, 401)\n",
    "    df_1mers_1_402 = rename_cols(df_1mers_1_402, 402)\n",
    "    df_1mers_1_404 = rename_cols(df_1mers_1_404, 404)\n",
    "    df_1mers_2_401 = rename_cols(df_1mers_2_401, 401)\n",
    "    df_1mers_2_402 = rename_cols(df_1mers_2_402, 402)\n",
    "    df_1mers_2_404 = rename_cols(df_1mers_2_404, 404)\n",
    "\n",
    "    ## Merge all 4 serotypes and process\n",
    "    #make dataframe with all order values so can order to this:\n",
    "    merged = pd.DataFrame({'overall_order':range(1,alignment.get_alignment_length())}) \n",
    "    \n",
    "    \n",
    "    #combine all 4 serotypes\n",
    "    merged = pd.merge(left=merged, right=df_1mers_1_401, left_on='overall_order',right_on='order+gaps_1_401',how='outer')\n",
    "    merged = pd.merge(left=merged, right=df_1mers_1_402, left_on='overall_order',right_on='order+gaps_1_402',how='outer')\n",
    "    merged = pd.merge(left=merged, right=df_1mers_1_404, left_on='overall_order',right_on='order+gaps_1_404',how='outer')\n",
    "    merged = pd.merge(left=merged, right=df_1mers_2_401, left_on='overall_order',right_on='order+gaps_2_401',how='outer')\n",
    "    merged = pd.merge(left=merged, right=df_1mers_2_402, left_on='overall_order',right_on='order+gaps_2_402',how='outer')\n",
    "    merged = pd.merge(left=merged, right=df_1mers_2_404, left_on='overall_order',right_on='order+gaps_2_404',how='outer')\n",
    "\n",
    "    \n",
    "    # combine amino acids for making X-tick labels that are basically the alignment\n",
    "    for i in [1,2]:\n",
    "        for mhc in [401,402,404]:\n",
    "            merged['1mers_'+str(i)+'_'+str(mhc)].fillna('-',inplace=True)\n",
    "    merged['combo_P1'] = merged['1mers_2_401']+\"\\n\"+ merged['1mers_1_401']\n",
    "\n",
    "    #save the order as string (new column):\n",
    "    merged['overall_order_str'] = merged['overall_order'].astype(str) #have to convert to string in order for all values to show up on x-axis to be replaced by AAs\n",
    "\n",
    "    \n",
    "    #Color core in black, rest in grey \n",
    "    merged['color'] = 'grey'\n",
    "    merged.loc[((merged['overall_order']>=serotype_blank_min['overall']+9)&(merged['overall_order']<=serotype_blank_max['overall']-6)),'color'] = 'black'\n",
    "\n",
    "\n",
    "    # PLOT #####\n",
    "    plt.rcParams.update({'font.size': 12})\n",
    "\n",
    "    for index in [serotype_blank_min['index']]:\n",
    "        print('here')\n",
    "        fig, ax1 = plt.subplots(figsize=(2.5,6))\n",
    "                \n",
    "        for i in range(1,16):\n",
    "\n",
    "            plt.plot(merged['overall_order_str'], merged['mod={}_1_401'.format(str(i))]+0 , c='blue',alpha=0.5)\n",
    "            plt.plot(merged['overall_order_str'], merged['mod={}_2_401'.format(str(i))]+10, c='blue')\n",
    "            plt.plot(merged['overall_order_str'], merged['mod={}_1_402'.format(str(i))]+20, c='red',alpha=0.5)\n",
    "            plt.plot(merged['overall_order_str'], merged['mod={}_2_402'.format(str(i))]+30, c='red')\n",
    "            plt.plot(merged['overall_order_str'], merged['mod={}_1_404'.format(str(i))]+40, c='grey',alpha=0.5)\n",
    "            plt.plot(merged['overall_order_str'], merged['mod={}_2_404'.format(str(i))]+50, c='grey')\n",
    "            \n",
    "\n",
    "        ax1.set_xticklabels(merged['combo_P1']) ## label with amino acid\n",
    "\n",
    "        if narrow_kw == 'narrow':\n",
    "            plt.xlim(index,index+20)\n",
    "        else:\n",
    "            plt.xlim(index,index+23)\n",
    "\n",
    "                \n",
    "        plt.ylim(0, 90)\n",
    "\n",
    "        for xtick, color in zip(ax1.get_xticklabels(),merged['color']):\n",
    "            xtick.set_color(color)\n",
    "\n",
    "        ax1.spines['top'].set_visible(False)\n",
    "        ax1.spines['right'].set_visible(False)\n",
    "        ax1.spines['left'].set_visible(False)\n",
    "        plt.yticks([])  \n",
    "        plt.xticks(fontname='Andale Mono')\n",
    "        plt.title(str(index)+\"-\"+str(index+23))\n",
    "\n",
    "        plt.show()\n",
    "\n",
    "    return\n",
    "    \n",
    "\n",
    "### excludes the overlapping linker variants:\n",
    "serotype_blank_min = {1:636+3,2:650+3,'overall':655,'index':654+3}\n",
    "serotype_blank_max = {1:647,2:661,'overall':678}\n",
    "everything_else_covid('narrow')\n",
    "\n",
    "serotype_blank_min = {1:510+3,2:524+3,'overall':529,'index':528+3}\n",
    "serotype_blank_max = {1:521,2:535,'overall':552}\n",
    "everything_else_covid('narrow')\n",
    "\n",
    "serotype_blank_min = {1:449+3,2:462+3,'overall':467,'index':466+3}\n",
    "serotype_blank_max = {1:459,2:473,'overall':490}\n",
    "everything_else_covid('narrow')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dengue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def everything_else(narrow_kw=''):\n",
    "    #new:\n",
    "    directory = '/Proteome Peptides/Dengue - used to generate lists'\n",
    "\n",
    "    ## Dengue 1 ###\n",
    "    uniprot = 'sp|P17763|POLG_DEN1W'\n",
    "    fname = '/dengue_type1_UP000002500.fasta'\n",
    "    data_merged_1, df_1mers_1 = do_it_targeted(uniprot, fname, 1,'dengue',data_dengue,'401',directory)\n",
    "\n",
    "    ## Dengue 2 ###\n",
    "    uniprot = 'tr|O09234|O09234_DEN26'\n",
    "    fname = '/dengue_type2_UP000180751.fasta'\n",
    "    data_merged_2, df_1mers_2 = do_it_targeted(uniprot, fname, 2,'dengue',data_dengue,'401',directory)\n",
    "    \n",
    "    ## Dengue 3 ###\n",
    "    uniprot = 'sp|P27915|POLG_DEN3P'\n",
    "    fname = '/dengue_type3_UP000007200.fasta'\n",
    "    data_merged_3, df_1mers_3 = do_it_targeted(uniprot, fname, 3,'dengue',data_dengue,'401',directory)\n",
    "\n",
    "    ## Dengue 4 ###\n",
    "    uniprot = 'sp|Q58HT7|POLG_DEN4P'\n",
    "    fname = '/dengue_type4_UP000000275.fasta'\n",
    "    data_merged_4, df_1mers_4 = do_it_targeted(uniprot, fname, 4,'dengue',data_dengue,'401',directory)\n",
    "\n",
    "\n",
    "\n",
    "    # find where there are gaps in alignment and add gaps in the ordered dataframe\n",
    "    df_1mers_1 = add_gaps(df_1mers_1, 'sp|P17763|POLG_DEN1W', 1, alignment_dengue)\n",
    "    df_1mers_2 = add_gaps(df_1mers_2, 'tr|O09234|O09234_DEN26',2,alignment_dengue)\n",
    "    df_1mers_3 = add_gaps(df_1mers_3, 'sp|P27915|POLG_DEN3P', 3, alignment_dengue)\n",
    "    df_1mers_4 = add_gaps(df_1mers_4, 'sp|Q58HT7|POLG_DEN4P', 4, alignment_dengue)\n",
    "\n",
    "\n",
    "\n",
    "    ## Merge all 4 serotypes and process\n",
    "\n",
    "    #make dataframe with all order values so can order to this:\n",
    "    merged = pd.DataFrame({'overall_order':range(1,alignment_dengue.get_alignment_length())}) \n",
    "\n",
    "    #combine all 4 serotypes\n",
    "    merged = pd.merge(left=merged, right=df_1mers_1, left_on='overall_order',right_on='order+gaps_1',how='outer')\n",
    "    merged = pd.merge(left=merged, right=df_1mers_2, left_on='overall_order',right_on='order+gaps_2',how='outer')\n",
    "    merged = pd.merge(left=merged, right=df_1mers_3, left_on='overall_order',right_on='order+gaps_3',how='outer')\n",
    "    merged = pd.merge(left=merged, right=df_1mers_4, left_on='overall_order',right_on='order+gaps_4',how='outer')\n",
    "\n",
    "\n",
    "    # combine amino acids for making X-tick labels that are basically the alignment\n",
    "    for i in [1,2,3,4]:\n",
    "        merged['1mers_'+str(i)].fillna('-',inplace=True)\n",
    "    merged['combo_P1'] = merged['1mers_4']+\"\\n\"+ merged['1mers_3']+\"\\n\"+ merged['1mers_2']+\"\\n\"+ merged['1mers_1']\n",
    "\n",
    "    #save the order as string (new column):\n",
    "    merged['overall_order_str'] = merged['overall_order'].astype(str) #have to convert to string in order for all values to show up on x-axis to be replaced by AAs\n",
    "\n",
    "    \n",
    "    #Color core in black, rest in grey \n",
    "    merged['color'] = 'grey'\n",
    "    merged.loc[((merged['overall_order']>=serotype_blank_min['overall']+9)&(merged['overall_order']<=serotype_blank_max['overall']-6)),'color'] = 'black'\n",
    "\n",
    "    \n",
    "    # PLOT #####\n",
    "    plt.rcParams.update({'font.size': 14})\n",
    "\n",
    "    color_dict = {1:'blue',\n",
    "                  2:'purple',\n",
    "                  3:'red',\n",
    "                  4:'grey'\n",
    "                 }\n",
    "\n",
    "    for index in [serotype_blank_min['index']]:\n",
    "        fig, ax1 = plt.subplots(figsize=(3,5))\n",
    "        for serotype in [1,2,3,4]:\n",
    "            for i in range(1,16):\n",
    "                temp = merged['mod={}_{}'.format(str(i), str(serotype))]+(serotype-1)*10\n",
    "                plt.plot(merged['overall_order_str'],temp, c=color_dict[serotype])#,marker='_')#,s=100)\n",
    "\n",
    "\n",
    "        ax1.set_xticklabels(merged['combo_P1']) ## label with amino acid\n",
    "\n",
    "\n",
    "        if narrow_kw=='narrow':\n",
    "            plt.xlim(index,index+20)\n",
    "        else:\n",
    "            plt.xlim(index,index+23)\n",
    "        plt.ylim(0, 60)\n",
    "\n",
    "        for xtick, color in zip(ax1.get_xticklabels(),merged['color']):\n",
    "            xtick.set_color(color)\n",
    "\n",
    "        ax1.spines['top'].set_visible(False)\n",
    "        ax1.spines['right'].set_visible(False)\n",
    "        ax1.spines['left'].set_visible(False)\n",
    "        plt.yticks([])  \n",
    "        plt.xticks(fontname='Andale Mono')\n",
    "        plt.title(str(index)+\"-\"+str(index+23))\n",
    "\n",
    "        plt.show()\n",
    "\n",
    "    \n",
    "    return\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "## Narrow these so don't include linker sequences\n",
    "serotype_blank_min = {1:390+3,2:390+3,3:390+2,4:388+3,'overall':390,'index':389+3}\n",
    "serotype_blank_max = {1:401,2:401,3:401,4:399,'overall':413}\n",
    "everything_else('narrow')\n",
    "\n",
    "serotype_blank_min = {1:3256+3,2:3255+3,3:3254+3,4:3252+3,'overall':3260,'index':3259+3}\n",
    "serotype_blank_max = {1:3267,2:3266,3:3265,4:3263,'overall':3283}\n",
    "everything_else('narrow')\n",
    "\n",
    "serotype_blank_min = {1:1872+3,2:1871+3,3:1870+3,4:1870+3,'overall':1874,'index':1873+3}\n",
    "serotype_blank_max = {1:1883,2:1883,3:1881,4:1881,'overall':1897}\n",
    "everything_else('narrow')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
